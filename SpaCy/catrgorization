import spacy
import json
from spacy.training import Example
from tqdm import tqdm

def load_data_from_file(file_path):
    """
    Load categorization data from a file.
    Expected format: JSON file with categories as keys and lists of texts as values
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
        return data
    except FileNotFoundError:
        print(f"Error: File {file_path} not found.")
        return None
    except json.JSONDecodeError:
        print(f"Error: File {file_path} is not in valid JSON format.")
        return None

def prepare_training_data(data):
    """Convert data into training examples"""
    train_data = []
    for category, texts in data.items():
        for text in texts:
            cats = {cat: 1.0 if cat == category else 0.0 for cat in data.keys()}
            train_data.append((text, {"cats": cats}))
    return train_data

# Load data from file
data_file_path = "categories_data.json"
data = load_data_from_file(data_file_path)

if data:
    # Initialize spaCy with a blank model
    nlp = spacy.blank("en")
    
    # Add text categorizer to the pipeline
    if "textcat" not in nlp.pipe_names:
        # Configure the text categorizer
        textcat = nlp.add_pipe("textcat", last=True)
        
        # Add categories
        for category in data.keys():
            textcat.add_label(category)
            
        # Initialize the model with some data to avoid initialization error
        optimizer = nlp.initialize()
            
        # Prepare training data
        train_data = prepare_training_data(data)
        
        # Convert training data to spaCy's format
        train_examples = []
        for text, annotations in train_data:
            train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))
        
        # Training settings
        n_iter = 20
        
        # Train the model
        print("Training the model...")
        with tqdm(total=n_iter) as pbar:
            for _ in range(n_iter):
                losses = {}
                nlp.update(train_examples, sgd=optimizer, losses=losses)
                pbar.update(1)
                pbar.set_description(f"Loss: {losses['textcat']:.3f}")

    # Test the classifier
    test_text = "I am looking for kitchen appliances."
    doc = nlp(test_text)
    scores = doc.cats
    print(f"\nClassification for '{test_text}':")
    for category, score in scores.items():
        print(f"{category}: {score:.2f}")
else:
    print("Could not proceed with classification due to data loading error.")



